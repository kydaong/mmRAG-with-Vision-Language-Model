# mmRAG-with-Vision-Language-Model
This project implements a Multimodal Retrieval-Augmented Generation (RAG) pipeline that combines text and visual understanding using a Vision-Language Model (VLM). It enables querying across both documents and images, retrieving relevant multimodal context, and generating grounded responses.
